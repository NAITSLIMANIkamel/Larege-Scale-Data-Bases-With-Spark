{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "notebookName": "Spark-RDD-2021_solutions",
      "dashboards": [],
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "language": "python",
      "widgets": {},
      "notebookOrigID": 2832703719774903
    },
    "colab": {
      "name": "Copie de DecisionTressSparkML.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "levNDESpS1hT"
      ],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "59ad38d8-fb28-470f-a038-842f83d07a09"
        },
        "id": "kCaImCHx_2a_"
      },
      "source": [
        "* Master DAC, BDLE, 2021 \n",
        "* Author: Mohamed-Amine Baazizi\n",
        "* Affiliation: LIP6 - Faculté des Sciences - Sorbonne Université\n",
        "* Email: mohamed-amine.baazizi@lip6.fr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzEVmTXWQq-n"
      },
      "source": [
        "# Decision Tree in Spark ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "b15737ae-19bd-4b9f-b9f3-52388cc5e50e"
        },
        "id": "levNDESpS1hT"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## Préparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "b6afe82e-35d6-4358-9b79-8f56074e0908"
        },
        "id": "4pZBsez9S1hT"
      },
      "source": [
        "Vérifier que des ressources de calcul sont allouées à votre notebook est connecté (cf RAM  de disque indiqués en haut à droite) . Sinon cliquer sur le bouton connecter pour obtenir des ressources.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEjerqQ6Ink6"
      },
      "source": [
        "Pour accéder directement aux fichiers stockées sur votre google drive. Renseigner le code d'authentification lorsqu'il est demandé\n",
        "\n",
        "Ajuster le nom de votre dossier : MyDrive/ens/bdle/dir. **Remplacer dir **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7Dv93rsImuM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd87954c-d813-4c3f-f413-b7f655cd31d6"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "drive_dir = \"/content/drive/MyDrive/ens/bdle/dir\"\n",
        "os.makedirs(drive_dir, exist_ok=True)\n",
        "os.listdir(drive_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v9EXMl8aPZC"
      },
      "source": [
        "Installer pyspark et findspark :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zlwNHy1S8C2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a57391f-f05e-4b5d-f30a-e0df9b3ab44b"
      },
      "source": [
        "!pip install -q pyspark\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 281.3 MB 41 kB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 59.9 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnEmOd_zOUo0"
      },
      "source": [
        "Démarrer la session spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0ADH0J-VW7i"
      },
      "source": [
        "import os\n",
        "# !find /usr/local -name \"pyspark\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/usr/local/lib/python3.7/dist-packages/pyspark\"\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_WxQZB7TaUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c36c4bbe-5dac-4dee-9e12-b3bfedb90eda"
      },
      "source": [
        "# Principaux import\n",
        "import findspark\n",
        "from pyspark.sql import SparkSession \n",
        "from pyspark import SparkConf  \n",
        "\n",
        "# pour les dataframe et udf\n",
        "from pyspark.sql import *  \n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from datetime import *\n",
        "\n",
        "# pour le chronomètre\n",
        "import time\n",
        "\n",
        "# initialise les variables d'environnement pour spark\n",
        "findspark.init()\n",
        "\n",
        "# Démarrage session spark \n",
        "# --------------------------\n",
        "def demarrer_spark():\n",
        "  local = \"local[*]\"\n",
        "  appName = \"TP\"\n",
        "  configLocale = SparkConf().setAppName(appName).setMaster(local).\\\n",
        "  set(\"spark.executor.memory\", \"6G\").\\\n",
        "  set(\"spark.driver.memory\",\"6G\").\\\n",
        "  set(\"spark.sql.catalogImplementation\",\"in-memory\")\n",
        "  \n",
        "  spark = SparkSession.builder.config(conf = configLocale).getOrCreate()\n",
        "  sc = spark.sparkContext\n",
        "  sc.setLogLevel(\"ERROR\")\n",
        "  \n",
        "  spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\",\"-1\")\n",
        "\n",
        "  # On ajuste l'environnement d'exécution des requêtes à la taille du cluster (4 coeurs)\n",
        "  spark.conf.set(\"spark.sql.shuffle.partitions\",\"4\")    \n",
        "  print(\"session démarrée, son id est \", sc.applicationId)\n",
        "  return spark\n",
        "spark = demarrer_spark()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "session démarrée, son id est  local-1635498856257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "852847c4-bd45-4f9c-ae8b-2c704f389cf9"
        },
        "id": "fj9pUgrmGpLe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f1707906-c917-47ff-ee56-afc39681a3f7"
      },
      "source": [
        "# on utilise 8 partitions au lieu de 200 par défaut\n",
        "spark.conf.set(\"spark.sql.shuffle.partitions\", \"8\")\n",
        "print(\"Nombre de partitions utilisées : \", spark.conf.get(\"spark.sql.shuffle.partitions\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f1f16958891a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# on utilise 8 partitions au lieu de 200 par défaut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.sql.shuffle.partitions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nombre de partitions utilisées : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.sql.shuffle.partitions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHcVH-faR_1S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "41dd8b8e-d697-4efb-a1d2-cd34a08b3e7e"
        },
        "id": "NtjUaom1_2bC"
      },
      "source": [
        "## Test Exemple Cours\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlMUUoCNQ1fI"
      },
      "source": [
        "data = [[\"young\",\"high\",\"no\",\"fair\",\"no\"],\n",
        "        [\"young\",\"high\",\"no\",\"excellent\",\"no\"],\n",
        "        [\"middle\",\"high\",\"no\",\"fair\",\"yes\"],\n",
        "        [\"senior\",\"medium\",\"no\",\"fair\",\"yes\"],\n",
        "        [\"senior\",\"low\",\"yes\",\"fair\",\"yes\"],\n",
        "        [\"senior\",\"low\",\"yes\",\"excellent\",\"no\"],\n",
        "        [\"middle\",\"low\",\"yes\",\"excellent\",\"yes\"],\n",
        "        [\"young\",\"medium\",\"no\",\"fair\",\"no\"],\n",
        "        [\"young\",\"low\",\"yes\",\"fair\",\"yes\"],\n",
        "        [\"senior\",\"medium\",\"yes\",\"fair\",\"yes\"],\n",
        "        [\"young\",\"medium\",\"yes\",\"excellent\",\"yes\"],\n",
        "        [\"middle\",\"medium\",\"no\",\"excellent\",\"yes\"],\n",
        "        [\"middle\",\"high\",\"yes\",\"fair\",\"yes\"],\n",
        "        [\"senior\",\"medium\",\"no\",\"excellent\",\"no\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQa_aBglRt9A"
      },
      "source": [
        "df = spark.createDataFrame(spark.sparkContext.parallelize(data),'age string, income string, student string, rating string, label string')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUQAxazqVfwI"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "field = 'age'\n",
        "age_indexer = StringIndexer(inputCol=field, outputCol='indexed_'+field )\n",
        "df_age_idx=age_indexer.fit(df).transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPyn5g0YYGrt",
        "outputId": "06dd2254-a80b-4691-9de7-e09bfabd3772"
      },
      "source": [
        "df_age_idx.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+---------+-----+-----------+\n",
            "|   age|income|student|   rating|label|indexed_age|\n",
            "+------+------+-------+---------+-----+-----------+\n",
            "| young|  high|     no|     fair|   no|        1.0|\n",
            "| young|  high|     no|excellent|   no|        1.0|\n",
            "|middle|  high|     no|     fair|  yes|        2.0|\n",
            "|senior|medium|     no|     fair|  yes|        0.0|\n",
            "|senior|   low|    yes|     fair|  yes|        0.0|\n",
            "|senior|   low|    yes|excellent|   no|        0.0|\n",
            "|middle|   low|    yes|excellent|  yes|        2.0|\n",
            "| young|medium|     no|     fair|   no|        1.0|\n",
            "| young|   low|    yes|     fair|  yes|        1.0|\n",
            "|senior|medium|    yes|     fair|  yes|        0.0|\n",
            "| young|medium|    yes|excellent|  yes|        1.0|\n",
            "|middle|medium|     no|excellent|  yes|        2.0|\n",
            "|middle|  high|    yes|     fair|  yes|        2.0|\n",
            "|senior|medium|     no|excellent|   no|        0.0|\n",
            "+------+------+-------+---------+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VJAN_14YLgu"
      },
      "source": [
        "from pyspark.ml.feature import IndexToString\n",
        "age_rev_indexer= IndexToString(inputCol=age_indexer.getOutputCol(),outputCol='original_age')\n",
        "df_orig_age=age_rev_indexer.transform(df_age_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LxefDxPYanc",
        "outputId": "c76291b4-7dda-4853-9114-b1a46f9f926c"
      },
      "source": [
        "df_orig_age.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+---------+-----+-----------+------------+\n",
            "|   age|income|student|   rating|label|indexed_age|original_age|\n",
            "+------+------+-------+---------+-----+-----------+------------+\n",
            "| young|  high|     no|     fair|   no|        1.0|       young|\n",
            "| young|  high|     no|excellent|   no|        1.0|       young|\n",
            "|middle|  high|     no|     fair|  yes|        2.0|      middle|\n",
            "|senior|medium|     no|     fair|  yes|        0.0|      senior|\n",
            "|senior|   low|    yes|     fair|  yes|        0.0|      senior|\n",
            "|senior|   low|    yes|excellent|   no|        0.0|      senior|\n",
            "|middle|   low|    yes|excellent|  yes|        2.0|      middle|\n",
            "| young|medium|     no|     fair|   no|        1.0|       young|\n",
            "| young|   low|    yes|     fair|  yes|        1.0|       young|\n",
            "|senior|medium|    yes|     fair|  yes|        0.0|      senior|\n",
            "| young|medium|    yes|excellent|  yes|        1.0|       young|\n",
            "|middle|medium|     no|excellent|  yes|        2.0|      middle|\n",
            "|middle|  high|    yes|     fair|  yes|        2.0|      middle|\n",
            "|senior|medium|     no|excellent|   no|        0.0|      senior|\n",
            "+------+------+-------+---------+-----+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx6vwfWwYeOd"
      },
      "source": [
        "from pyspark.ml.feature import OneHotEncoder \n",
        "age_onehotenc= OneHotEncoder(inputCol=age_indexer.getOutputCol(),outputCol='cat_age') \n",
        "age_onehotenc.setDropLast(False)\n",
        "df_age_onehot= age_onehotenc.fit(df_age_idx).transform(df_age_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0PAUIxyZ81a",
        "outputId": "ef9d63a0-9cb3-4908-9427-4ab5c9450dac"
      },
      "source": [
        "df_age_onehot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+---------+-----+-----------+-------------+\n",
            "|   age|income|student|   rating|label|indexed_age|      cat_age|\n",
            "+------+------+-------+---------+-----+-----------+-------------+\n",
            "| young|  high|     no|     fair|   no|        1.0|(3,[1],[1.0])|\n",
            "| young|  high|     no|excellent|   no|        1.0|(3,[1],[1.0])|\n",
            "|middle|  high|     no|     fair|  yes|        2.0|(3,[2],[1.0])|\n",
            "|senior|medium|     no|     fair|  yes|        0.0|(3,[0],[1.0])|\n",
            "|senior|   low|    yes|     fair|  yes|        0.0|(3,[0],[1.0])|\n",
            "|senior|   low|    yes|excellent|   no|        0.0|(3,[0],[1.0])|\n",
            "|middle|   low|    yes|excellent|  yes|        2.0|(3,[2],[1.0])|\n",
            "| young|medium|     no|     fair|   no|        1.0|(3,[1],[1.0])|\n",
            "| young|   low|    yes|     fair|  yes|        1.0|(3,[1],[1.0])|\n",
            "|senior|medium|    yes|     fair|  yes|        0.0|(3,[0],[1.0])|\n",
            "| young|medium|    yes|excellent|  yes|        1.0|(3,[1],[1.0])|\n",
            "|middle|medium|     no|excellent|  yes|        2.0|(3,[2],[1.0])|\n",
            "|middle|  high|    yes|     fair|  yes|        2.0|(3,[2],[1.0])|\n",
            "|senior|medium|     no|excellent|   no|        0.0|(3,[0],[1.0])|\n",
            "+------+------+-------+---------+-----+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIWdjqJOaE1n"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "label = 'label'\n",
        "features_col= df.columns\n",
        "features_col.remove(label)\n",
        "prefix = 'indexed_'\n",
        "label_string_indexer= StringIndexer(inputCol=label, outputCol=prefix+label)\n",
        "features_str_col= list(map(lambda c:prefix+c, features_col))\n",
        "features_string_indexer= StringIndexer(inputCols=features_col,outputCols=features_str_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DUX9C7Fb6qO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gEKcpPJagHj"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler,VectorIndexer\n",
        "vec_assembler= VectorAssembler(inputCols= features_string_indexer.getOutputCols(),outputCol= 'vector')\n",
        "vec_indexer= VectorIndexer(inputCol='vector',outputCol='features', maxCategories=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kfpwliidb2rt",
        "outputId": "a507a26c-09a5-4c4b-9e38-8e3ae7f25b88"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "stages = [label_string_indexer,features_string_indexer,vec_assembler,vec_indexer]\n",
        "pipeline = Pipeline(stages = stages)\n",
        "train_data= pipeline.fit(df).transform(df)\n",
        "train_data.select(\"features\",\"indexed_label\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------+\n",
            "|         features|indexed_label|\n",
            "+-----------------+-------------+\n",
            "|[1.0,1.0,0.0,0.0]|          1.0|\n",
            "|[1.0,1.0,0.0,1.0]|          1.0|\n",
            "|[2.0,1.0,0.0,0.0]|          0.0|\n",
            "|        (4,[],[])|          0.0|\n",
            "|[0.0,2.0,1.0,0.0]|          0.0|\n",
            "|[0.0,2.0,1.0,1.0]|          1.0|\n",
            "|[2.0,2.0,1.0,1.0]|          0.0|\n",
            "|    (4,[0],[1.0])|          1.0|\n",
            "|[1.0,2.0,1.0,0.0]|          0.0|\n",
            "|    (4,[2],[1.0])|          0.0|\n",
            "|[1.0,0.0,1.0,1.0]|          0.0|\n",
            "|[2.0,0.0,0.0,1.0]|          0.0|\n",
            "|[2.0,1.0,1.0,0.0]|          0.0|\n",
            "|    (4,[3],[1.0])|          1.0|\n",
            "+-----------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss5i73jFbjR7"
      },
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassificationModel, DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol= \"indexed_label\")\n",
        "dtModel= dt.fit(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V348y4GweIHu",
        "outputId": "32402133-4e42-4d67-9ba8-d0f2dbaf9d8b"
      },
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassificationModel, DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol= \"label\")\n",
        "dtModel= dt.fit(train_data)\n",
        "dtModel.transform(train_data).select(\"features\",\"label\",\"prediction\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------+----------+\n",
            "|         features|indexed_label|prediction|\n",
            "+-----------------+-------------+----------+\n",
            "|[1.0,1.0,0.0,0.0]|          1.0|       1.0|\n",
            "|[1.0,1.0,0.0,1.0]|          1.0|       1.0|\n",
            "|[2.0,1.0,0.0,0.0]|          0.0|       0.0|\n",
            "|        (4,[],[])|          0.0|       0.0|\n",
            "|[0.0,2.0,1.0,0.0]|          0.0|       0.0|\n",
            "|[0.0,2.0,1.0,1.0]|          1.0|       1.0|\n",
            "|[2.0,2.0,1.0,1.0]|          0.0|       0.0|\n",
            "|    (4,[0],[1.0])|          1.0|       1.0|\n",
            "|[1.0,2.0,1.0,0.0]|          0.0|       0.0|\n",
            "|    (4,[2],[1.0])|          0.0|       0.0|\n",
            "|[1.0,0.0,1.0,1.0]|          0.0|       0.0|\n",
            "|[2.0,0.0,0.0,1.0]|          0.0|       0.0|\n",
            "|[2.0,1.0,1.0,0.0]|          0.0|       0.0|\n",
            "|    (4,[3],[1.0])|          1.0|       1.0|\n",
            "+-----------------+-------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "368jKKlRewq0",
        "outputId": "8fd8d7de-de9b-4e2f-e73c-6a925db03b1f"
      },
      "source": [
        "print(dtModel.toDebugString)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_1cca20a63964, depth=4, numNodes=13, numClasses=2, numFeatures=4\n",
            "  If (feature 0 in {2.0})\n",
            "   Predict: 0.0\n",
            "  Else (feature 0 not in {2.0})\n",
            "   If (feature 2 in {1.0})\n",
            "    If (feature 3 in {0.0})\n",
            "     Predict: 0.0\n",
            "    Else (feature 3 not in {0.0})\n",
            "     If (feature 0 in {1.0})\n",
            "      Predict: 0.0\n",
            "     Else (feature 0 not in {1.0})\n",
            "      Predict: 1.0\n",
            "   Else (feature 2 not in {1.0})\n",
            "    If (feature 0 in {0.0})\n",
            "     If (feature 3 in {0.0})\n",
            "      Predict: 0.0\n",
            "     Else (feature 3 not in {0.0})\n",
            "      Predict: 1.0\n",
            "    Else (feature 0 not in {0.0})\n",
            "     Predict: 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkOPy1MEfv0q"
      },
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "dt_paramGrid= ParamGridBuilder().addGrid(dt.maxBins, [40,42]).addGrid(dt.minInstancesPerNode, [10,100]).build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJEbfooehHnp"
      },
      "source": [
        "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol= \"label\")\n",
        "cv = CrossValidator(estimator=dt,estimatorParamMaps=dt_paramGrid ,evaluator=BinaryClassificationEvaluator(),numFolds=5,parallelism=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc6CDXL3kcDi",
        "outputId": "60f17e5c-3889-41fa-da9f-c6ef8b629b14"
      },
      "source": [
        "train_data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+---------+-----+-------------+-----------+--------------+---------------+--------------+-----------------+-----------------+\n",
            "|   age|income|student|   rating|label|indexed_label|indexed_age|indexed_income|indexed_student|indexed_rating|           vector|         features|\n",
            "+------+------+-------+---------+-----+-------------+-----------+--------------+---------------+--------------+-----------------+-----------------+\n",
            "| young|  high|     no|     fair|   no|          1.0|        1.0|           1.0|            0.0|           0.0|[1.0,1.0,0.0,0.0]|[1.0,1.0,0.0,0.0]|\n",
            "| young|  high|     no|excellent|   no|          1.0|        1.0|           1.0|            0.0|           1.0|[1.0,1.0,0.0,1.0]|[1.0,1.0,0.0,1.0]|\n",
            "|middle|  high|     no|     fair|  yes|          0.0|        2.0|           1.0|            0.0|           0.0|[2.0,1.0,0.0,0.0]|[2.0,1.0,0.0,0.0]|\n",
            "|senior|medium|     no|     fair|  yes|          0.0|        0.0|           0.0|            0.0|           0.0|        (4,[],[])|        (4,[],[])|\n",
            "|senior|   low|    yes|     fair|  yes|          0.0|        0.0|           2.0|            1.0|           0.0|[0.0,2.0,1.0,0.0]|[0.0,2.0,1.0,0.0]|\n",
            "|senior|   low|    yes|excellent|   no|          1.0|        0.0|           2.0|            1.0|           1.0|[0.0,2.0,1.0,1.0]|[0.0,2.0,1.0,1.0]|\n",
            "|middle|   low|    yes|excellent|  yes|          0.0|        2.0|           2.0|            1.0|           1.0|[2.0,2.0,1.0,1.0]|[2.0,2.0,1.0,1.0]|\n",
            "| young|medium|     no|     fair|   no|          1.0|        1.0|           0.0|            0.0|           0.0|    (4,[0],[1.0])|    (4,[0],[1.0])|\n",
            "| young|   low|    yes|     fair|  yes|          0.0|        1.0|           2.0|            1.0|           0.0|[1.0,2.0,1.0,0.0]|[1.0,2.0,1.0,0.0]|\n",
            "|senior|medium|    yes|     fair|  yes|          0.0|        0.0|           0.0|            1.0|           0.0|    (4,[2],[1.0])|    (4,[2],[1.0])|\n",
            "| young|medium|    yes|excellent|  yes|          0.0|        1.0|           0.0|            1.0|           1.0|[1.0,0.0,1.0,1.0]|[1.0,0.0,1.0,1.0]|\n",
            "|middle|medium|     no|excellent|  yes|          0.0|        2.0|           0.0|            0.0|           1.0|[2.0,0.0,0.0,1.0]|[2.0,0.0,0.0,1.0]|\n",
            "|middle|  high|    yes|     fair|  yes|          0.0|        2.0|           1.0|            1.0|           0.0|[2.0,1.0,1.0,0.0]|[2.0,1.0,1.0,0.0]|\n",
            "|senior|medium|     no|excellent|   no|          1.0|        0.0|           0.0|            0.0|           1.0|    (4,[3],[1.0])|    (4,[3],[1.0])|\n",
            "+------+------+-------+---------+-----+-------------+-----------+--------------+---------------+--------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqwCrIJwp-bR"
      },
      "source": [
        "train_data_final=train_data.select(\"features\",\"indexed_label\").withColumnRenamed(\"indexed_label\",\"label\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoJU20R4ji_H"
      },
      "source": [
        "\n",
        "cvModel=cv.fit(train_data_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NINPwN5spI01",
        "outputId": "8ea7baf6-db7c-4ebf-ea4d-d135d32b9aec"
      },
      "source": [
        "cvModel.transform(train_data_final).select(\"features\",\"label\",\"prediction\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+----------+\n",
            "|         features|label|prediction|\n",
            "+-----------------+-----+----------+\n",
            "|[1.0,1.0,0.0,0.0]|  1.0|       1.0|\n",
            "|[1.0,1.0,0.0,1.0]|  1.0|       1.0|\n",
            "|[2.0,1.0,0.0,0.0]|  0.0|       0.0|\n",
            "|        (4,[],[])|  0.0|       0.0|\n",
            "|[0.0,2.0,1.0,0.0]|  0.0|       0.0|\n",
            "|[0.0,2.0,1.0,1.0]|  1.0|       1.0|\n",
            "|[2.0,2.0,1.0,1.0]|  0.0|       0.0|\n",
            "|    (4,[0],[1.0])|  1.0|       1.0|\n",
            "|[1.0,2.0,1.0,0.0]|  0.0|       0.0|\n",
            "|    (4,[2],[1.0])|  0.0|       0.0|\n",
            "|[1.0,0.0,1.0,1.0]|  0.0|       0.0|\n",
            "|[2.0,0.0,0.0,1.0]|  0.0|       0.0|\n",
            "|[2.0,1.0,1.0,0.0]|  0.0|       0.0|\n",
            "|    (4,[3],[1.0])|  1.0|       1.0|\n",
            "+-----------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEyMsG96m9cb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "9931a596-3ea9-4d1f-b408-b3558647f934"
        },
        "id": "R5ZJa3iU_2bh"
      },
      "source": [
        "##Projct Data Loading\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z5BQvWCnBHO"
      },
      "source": [
        ""
      ]
    }
  ]
}