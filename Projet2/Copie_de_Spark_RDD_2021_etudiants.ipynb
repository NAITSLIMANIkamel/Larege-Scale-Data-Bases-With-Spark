{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "notebookName": "Spark-RDD-2021_solutions",
      "notebookOrigID": 2832703719774903,
      "widgets": {}
    },
    "colab": {
      "name": "Copie de Spark-RDD-2021-etudiants.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "R5ZJa3iU_2bh"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCaImCHx_2a_"
      },
      "source": [
        "* Master DAC, BDLE, 2021 \n",
        "* Author: Mohamed-Amine Baazizi\n",
        "* Affiliation: LIP6 - Faculté des Sciences - Sorbonne Université\n",
        "* Email: mohamed-amine.baazizi@lip6.fr\n",
        "\n",
        "# Map-Reduce in Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee9AXss0_2bB"
      },
      "source": [
        "The goal of this lab is to write programs in the Map-Reduce paradigm using the RDD-python API of Spark. \n",
        "The API for documentation is available here:\n",
        "\n",
        "- https://spark.apache.org/docs/latest/api/python/reference/pyspark.html\n",
        "\n",
        "\n",
        "You are expected to use the following higher order functions like `map, flatMap, filter, reduceByKey, groupByKey, join, zipWithIndex` and the standard relational operators `union, intersection, subtract, join` and to favor functional-style programming."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPlI6WHxAMHj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "levNDESpS1hT"
      },
      "source": [
        "## Préparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pZBsez9S1hT"
      },
      "source": [
        "Vérifier que des ressources de calcul sont allouées à votre notebook est connecté (cf RAM  de disque indiqués en haut à droite) . Sinon cliquer sur le bouton connecter pour obtenir des ressources.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEjerqQ6Ink6"
      },
      "source": [
        "Pour accéder directement aux fichiers stockées sur votre google drive. Renseigner le code d'authentification lorsqu'il est demandé\n",
        "\n",
        "Ajuster le nom de votre dossier : MyDrive/ens/bdle/DM1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7Dv93rsImuM",
        "outputId": "109f4256-4948-47f2-814b-ba460898460c"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "drive_dir = \"/content/drive/MyDrive/ens/bdle/SparkMR\"\n",
        "os.makedirs(drive_dir, exist_ok=True)\n",
        "os.listdir(drive_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v9EXMl8aPZC"
      },
      "source": [
        "Installer pyspark et findspark :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zlwNHy1S8C2",
        "outputId": "92648bc6-5a9f-4374-eb26-2913a34ca289"
      },
      "source": [
        "!pip install -q pyspark\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 67 kB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 54.6 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnEmOd_zOUo0"
      },
      "source": [
        "Démarrer la session spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0ADH0J-VW7i"
      },
      "source": [
        "import os\n",
        "# !find /usr/local -name \"pyspark\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/usr/local/lib/python3.7/dist-packages/pyspark\"\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_WxQZB7TaUC",
        "outputId": "352eb592-6e08-4bbd-edde-821985c223d7"
      },
      "source": [
        "# Principaux import\n",
        "import findspark\n",
        "from pyspark.sql import SparkSession \n",
        "from pyspark import SparkConf  \n",
        "\n",
        "# pour les dataframe et udf\n",
        "from pyspark.sql import *  \n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from datetime import *\n",
        "\n",
        "# pour le chronomètre\n",
        "import time\n",
        "\n",
        "# initialise les variables d'environnement pour spark\n",
        "findspark.init()\n",
        "\n",
        "# Démarrage session spark \n",
        "# --------------------------\n",
        "def demarrer_spark():\n",
        "  local = \"local[*]\"\n",
        "  appName = \"TP\"\n",
        "  configLocale = SparkConf().setAppName(appName).setMaster(local).\\\n",
        "  set(\"spark.executor.memory\", \"6G\").\\\n",
        "  set(\"spark.driver.memory\",\"6G\").\\\n",
        "  set(\"spark.sql.catalogImplementation\",\"in-memory\")\n",
        "  \n",
        "  spark = SparkSession.builder.config(conf = configLocale).getOrCreate()\n",
        "  sc = spark.sparkContext\n",
        "  sc.setLogLevel(\"ERROR\")\n",
        "  \n",
        "  spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\",\"-1\")\n",
        "\n",
        "  # On ajuste l'environnement d'exécution des requêtes à la taille du cluster (4 coeurs)\n",
        "  spark.conf.set(\"spark.sql.shuffle.partitions\",\"4\")    \n",
        "  print(\"session démarrée, son id est \", sc.applicationId)\n",
        "  return spark\n",
        "spark = demarrer_spark()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "session démarrée, son id est  local-1634288857445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fj9pUgrmGpLe",
        "outputId": "199894f6-ac78-4df3-c0f6-2d9c90e5e128"
      },
      "source": [
        "# on utilise 8 partitions au lieu de 200 par défaut\n",
        "spark.conf.set(\"spark.sql.shuffle.partitions\", \"8\")\n",
        "print(\"Nombre de partitions utilisées : \", spark.conf.get(\"spark.sql.shuffle.partitions\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de partitions utilisées :  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtjUaom1_2bC"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnpzRKcuA9Yi",
        "outputId": "58416d69-6c6b-4b83-d44d-6763cbe1a90c"
      },
      "source": [
        "# URL du dossier PUBLIC_DATASET contenant des fichiers de données pour les TP\n",
        "# ---------------------------------------------------------------------------\n",
        "# en cas de problème avec le téléchargement des datasets, aller directement sur l'URL ci-dessous\n",
        "PUBLIC_DATASET_URL = \"https://nuage.lip6.fr/s/H3bpyRGgnCq2NR4\" \n",
        "PUBLIC_DATASET=PUBLIC_DATASET_URL + \"/download?path=\"\n",
        "\n",
        "print(\"URL pour les datasets \", PUBLIC_DATASET_URL)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "URL pour les datasets  https://nuage.lip6.fr/s/H3bpyRGgnCq2NR4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PecIszauBHx7",
        "outputId": "fe15ea2a-dd0f-40b7-e7a5-e4fac30887f3"
      },
      "source": [
        "import os\n",
        "from urllib import request\n",
        "\n",
        "def load_file(file):\n",
        "  if(os.path.isfile(file)):\n",
        "    print(file, \"is already stored\")\n",
        "  else:\n",
        "    url = PUBLIC_DATASET + \"/wordcount/\" + file\n",
        "    print(\"downloading from URL: \", url, \"save in : \" + drive_dir   + \"/\" + file)\n",
        "    request.urlretrieve(url , drive_dir + \"/\"  + file)\n",
        "\n",
        "load_file(\"smallwordcount.txt\")\n",
        "\n",
        "# Liste des fichiers de IMDB\n",
        "os.listdir(drive_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading from URL:  https://nuage.lip6.fr/s/H3bpyRGgnCq2NR4/download?path=/wordcount/smallwordcount.txt save in : /content/drive/MyDrive/ens/bdle/SparkMR/smallwordcount.txt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['smallwordcount.txt']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jFz_v1f_2bC"
      },
      "source": [
        "#size of displayed elements\n",
        "n=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJxVYsj4_2bE"
      },
      "source": [
        "## Simplified TF*IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlMsPzZe_2bF"
      },
      "source": [
        "Write instructions to compute the simplified version of TF*IDF for a synthetic corpus of words.\n",
        "The input data is an RDD of pairs $$(d_i, [w_j])$$\n",
        "where $$d_i \\text{ is a document identifier and } [w_i] \\text{ a list of words associated to } d_i \\text{ with possible repetition }$$\n",
        "\n",
        "You are expected to produce an RDD of triples $$(d_l, w_m,  tf \\times idf)$$ \n",
        "where $$tf \\text{ is the number of occurrence of } w_m \\text{ in } d_l$$\n",
        "and $$ idf \\text{ is the inverse of the number of documents where } w_m \\text{ appears }  $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmvyUaX4BqvK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VozqQ8fQ_2bF",
        "outputId": "efbef686-4099-485d-95e6-79f89cad78ad"
      },
      "source": [
        "dataset = ['d1,one fish two fish','d2,red fish blue', 'd3,one red bird']\n",
        "data = spark.sparkContext.parallelize(dataset)\n",
        "lines = data.filter(lambda x: x!='')\\\n",
        ".map(lambda x : x.split(\",\")).map(lambda x:(x[0],x[1].split(\" \")))\n",
        "lines.take(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('d1', ['one', 'fish', 'two', 'fish']),\n",
              " ('d2', ['red', 'fish', 'blue']),\n",
              " ('d3', ['one', 'red', 'bird'])]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhTlzQBUlpCf",
        "outputId": "4381c149-4c0d-4bbf-d0b2-da4a86d832b1"
      },
      "source": [
        "count = data.count()\n",
        "count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6I4jiUe_2bG"
      },
      "source": [
        "complete the stub of `combine` which is python function that combines each word in `list` with `word` given as argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AihTGDo0_2bH"
      },
      "source": [
        "def combine(list_, word):\n",
        "  res=map(lambda x : (x,word),list_)\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duRmK0yS_2bH",
        "outputId": "321cab1f-a260-4bba-fa84-7ba3aae99e31"
      },
      "source": [
        "list_ = ['d3', 'one', 'red', 'bird']\n",
        "word = 'd1'\n",
        "combine(list_,word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<map at 0x7fa3c382eb90>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FaUj-Hc_2bI"
      },
      "source": [
        "starting from `lines` produce and RDD of all pairs $$(d_i, w_j)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVn7-skp_2bJ",
        "outputId": "502715b4-3741-47ac-c6b1-d12971877c5c"
      },
      "source": [
        "word_doc = lines.flatMap(lambda x: [ (x[0],w) for w in x[1] ])\n",
        "word_doc.take(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('d1', 'one'),\n",
              " ('d1', 'fish'),\n",
              " ('d1', 'two'),\n",
              " ('d1', 'fish'),\n",
              " ('d2', 'red'),\n",
              " ('d2', 'fish'),\n",
              " ('d2', 'blue'),\n",
              " ('d3', 'one'),\n",
              " ('d3', 'red'),\n",
              " ('d3', 'bird')]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wILBLbgB_2bK"
      },
      "source": [
        "def add(a,b):\n",
        "  return a+b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnxzATVg_2bK"
      },
      "source": [
        "For each pair (document,word), count its frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1-pKl1H_2bK",
        "outputId": "1ae4ee4d-be8b-4504-b5b4-eba367fa8be8"
      },
      "source": [
        "freq_word = word_doc.map(lambda x : (x,1)).reduceByKey(add)\n",
        "freq_word.take(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(('d1', 'one'), 1),\n",
              " (('d2', 'fish'), 1),\n",
              " (('d3', 'one'), 1),\n",
              " (('d3', 'red'), 1),\n",
              " (('d1', 'fish'), 2),\n",
              " (('d1', 'two'), 1),\n",
              " (('d2', 'red'), 1),\n",
              " (('d2', 'blue'), 1),\n",
              " (('d3', 'bird'), 1)]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNqc70jpjSig"
      },
      "source": [
        "for each word, produce a pair (d,freq) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMlY-JFZkloL",
        "outputId": "0f40a529-b020-4f8b-dd8b-e8ce467b0a75"
      },
      "source": [
        "freq_word_bis = freq_word.map(lambda freq_word :(freq_word[0][1],( freq_word[0][0],freq_word[1])))\n",
        "freq_word_bis.take(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('one', ('d1', 1)),\n",
              " ('fish', ('d2', 1)),\n",
              " ('one', ('d3', 1)),\n",
              " ('red', ('d3', 1)),\n",
              " ('fish', ('d1', 2)),\n",
              " ('two', ('d1', 1)),\n",
              " ('red', ('d2', 1)),\n",
              " ('blue', ('d2', 1)),\n",
              " ('bird', ('d3', 1))]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR-GrBQrqMlx"
      },
      "source": [
        "for each word, compute its document frequency, i.e # of documents in which it appears"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBXOJRVGjQo5",
        "outputId": "45e09095-6585-449c-d894-d6490358f711"
      },
      "source": [
        "doc_freq = freq_word_bis.groupByKey().map(lambda x : (x[0], len(dataset)/len(x[1])))\n",
        "doc_freq.take(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('fish', 1.5),\n",
              " ('two', 3.0),\n",
              " ('bird', 3.0),\n",
              " ('one', 1.5),\n",
              " ('red', 1.5),\n",
              " ('blue', 3.0)]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6gugWm3_2bM"
      },
      "source": [
        "for each word, compute its simplified score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bUg0AUOkZxq",
        "outputId": "97bb46e6-4384-4440-b5d2-c769b799d250"
      },
      "source": [
        "final = freq_word_bis.join(doc_freq).map(lambda x : (x[0],x[1][0][0],x[1][0][1]*x[1][1]))\n",
        "final.take(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('two', 'd1', 3.0),\n",
              " ('bird', 'd3', 3.0),\n",
              " ('red', 'd3', 1.5),\n",
              " ('red', 'd2', 1.5),\n",
              " ('blue', 'd2', 3.0),\n",
              " ('fish', 'd2', 1.5),\n",
              " ('fish', 'd1', 3.0),\n",
              " ('one', 'd1', 1.5),\n",
              " ('one', 'd3', 1.5)]"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A1Ky2-7_2bN"
      },
      "source": [
        "## Text analytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2eBlT4G_2bN"
      },
      "source": [
        "The goal is to compute the SPMI (simplified pointwise mutual information) metric for words in a corpus.\n",
        "Given two words, a and b, \n",
        "\n",
        "$$SPMI(a, b) =  P(ab) / (P(a) * P(b)$$\n",
        "where $$P(ab) \\text{ is the probability of two words coming one after the other, and } P(a), P(b) \\text{ the probabilities of the words a and b, respectively} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg41kQfy_2bN"
      },
      "source": [
        "def removespecialchars (word) :\n",
        "    charstoremove = ['[',']','*','#','.','_',':','?','!',',',';','“','”','\\n'] \n",
        "    for ch in word:\n",
        "        if ch in charstoremove:\n",
        "            word = word.replace(ch,'',)\n",
        "    return word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjrIcZop_2bO"
      },
      "source": [
        "Read file in utf-8 using use_unicode=False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_UnSpCf_2bO"
      },
      "source": [
        "dataset =''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFfXLzxX_2bP",
        "outputId": "7e2f4d14-2e29-4b3e-c0c4-c82a4a538b9a"
      },
      "source": [
        "data = spark.sparkContext.textFile(drive_dir+\"/smallwordcount.txt\", use_unicode=\"False\")\n",
        "print(\"before filtering there are %d lines\" % data.count())\n",
        "# data.take(n)\n",
        "lines = data.filter(lambda x: x!='')\\\n",
        ".map(lambda x:removespecialchars(x))\\\n",
        ".map(lambda x : x.split(\" \"))\n",
        "print(\"after filtering there are %d lines\" % lines.count())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before filtering there are 14594 lines\n",
            "after filtering there are 12153 lines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JZEGq1c_2bP"
      },
      "source": [
        "retrieve the list of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7omXEru_2bP",
        "outputId": "b8db64ff-d966-490d-d09e-490304f3931a"
      },
      "source": [
        "words = lines.flatMap(lambda w:w).filter(lambda w:len(w)>0)\n",
        "words.take(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The',\n",
              " 'Project',\n",
              " 'Gutenberg',\n",
              " 'EBook',\n",
              " 'of',\n",
              " 'Pride',\n",
              " 'and',\n",
              " 'Prejudice',\n",
              " 'by',\n",
              " 'Jane',\n",
              " 'Austen',\n",
              " 'This',\n",
              " 'eBook',\n",
              " 'is',\n",
              " 'for',\n",
              " 'the',\n",
              " 'use',\n",
              " 'of',\n",
              " 'anyone',\n",
              " 'anywhere',\n",
              " 'at',\n",
              " 'no',\n",
              " 'cost',\n",
              " 'and',\n",
              " 'with',\n",
              " 'almost',\n",
              " 'no',\n",
              " 'restrictions',\n",
              " 'whatsoever',\n",
              " 'You',\n",
              " 'may',\n",
              " 'copy',\n",
              " 'it',\n",
              " 'give',\n",
              " 'it',\n",
              " 'away',\n",
              " 'or',\n",
              " 're-use',\n",
              " 'it',\n",
              " 'under',\n",
              " 'the',\n",
              " 'terms',\n",
              " 'of',\n",
              " 'the',\n",
              " 'Project',\n",
              " 'Gutenberg',\n",
              " 'License',\n",
              " 'included',\n",
              " 'with',\n",
              " 'this']"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnck6h-F_2bQ"
      },
      "source": [
        "compute the frequency of each word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MTLQJCFj_2bQ",
        "outputId": "319ea96b-0afe-4a14-8d30-63953ed2575c"
      },
      "source": [
        "wordcount = words.map(w,(w,1)).reduceByKey(add)\n",
        "wordcount.take(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-f9c5dad108df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwordcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduceByKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwordcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'w' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUqkVCec_2bS"
      },
      "source": [
        "count the number of distinct words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwOc8G03_2bS",
        "outputId": "eea0a429-7a56-4491-eba3-342ff3c0cc75"
      },
      "source": [
        "nb_distinct_words = wordcount.count()\n",
        "nb_distinct_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7761"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEf0uZVD_2bT"
      },
      "source": [
        "compute the proba of each word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL1QhrU7_2bU",
        "outputId": "dfb8bc4a-2a82-498b-edac-e0f2f02f443b"
      },
      "source": [
        "word_proba = wordcount.#...\n",
        "word_proba.take(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-107-a86d04eee84c>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    word_proba = wordcount.map(x:(x[0],x[1]/N))\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ1iMxDs_2bW"
      },
      "source": [
        "Collocation of words: build an RDD of bigrams. A bigram is a pair of words appearing in consecutive order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HsXxn6C_2bX",
        "outputId": "75a94195-48be-4b60-b8e6-1c408f893b50"
      },
      "source": [
        "words_index = words.#...\n",
        "words_index.take(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0, 'The'),\n",
              " (1, 'Project'),\n",
              " (2, 'Gutenberg'),\n",
              " (3, 'EBook'),\n",
              " (4, 'of'),\n",
              " (5, 'Pride'),\n",
              " (6, 'and'),\n",
              " (7, 'Prejudice'),\n",
              " (8, 'by'),\n",
              " (9, 'Jane')]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlqZ5MFR_2bY",
        "outputId": "a30b8ae3-e458-4938-9913-faca317e68ed"
      },
      "source": [
        "words_index_other = words_index.#...\n",
        "words_index_other.take(n)                                                 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(-1, 'The'),\n",
              " (0, 'Project'),\n",
              " (1, 'Gutenberg'),\n",
              " (2, 'EBook'),\n",
              " (3, 'of'),\n",
              " (4, 'Pride'),\n",
              " (5, 'and'),\n",
              " (6, 'Prejudice'),\n",
              " (7, 'by'),\n",
              " (8, 'Jane')]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5emou1DL_2bZ",
        "outputId": "62d5043e-242a-444c-a6a4-4178df1a9c80"
      },
      "source": [
        "bigram = words_index.#...\n",
        "bigram.take(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-117-bdad354ec1f2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    bigram = words_index.join(words_index_other).map(lambda x, x[1])\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9GWKQDp_2ba"
      },
      "source": [
        "count the fequency of each bigram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM0XGm_F_2ba",
        "outputId": "774449cd-ab6b-4351-897c-f59e9dbbbb79"
      },
      "source": [
        "bigramcount = bigram.#...\n",
        "bigramcount.take(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(('use', 'of'), 8),\n",
              " (('at', 'no'), 6),\n",
              " (('the', 'terms'), 14),\n",
              " (('12', '2019'), 1),\n",
              " (('PREJUDICE', 'Produced'), 1),\n",
              " (('Volunteers', 'and'), 3),\n",
              " (('and', 'Prejudice'), 4),\n",
              " (('Chapter', '4'), 2),\n",
              " (('Chapter', '10'), 2),\n",
              " (('Chapter', '12'), 2)]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-vGmlff_2bb"
      },
      "source": [
        "attach to each bigram the probability of its words, i.e. $$P(a) * P(b)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn_zMw8g_2bb",
        "outputId": "11489ae3-6018-4425-eaf9-c584802c6479"
      },
      "source": [
        "bigramproba = bigramcount.#...\n",
        "bigramproba.take(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(('of', 'Pride'), 0.0003678706936006188),\n",
              " (('Title', 'Pride'), 9.961296875185996e-08),\n",
              " (('vain', 'Pride'), 1.7930334375334792e-06),\n",
              " (('mine', 'Pride'), 1.4941945312778994e-06),\n",
              " (('cover', 'Pride'), 1.9922593750371993e-07),\n",
              " (('of', 'them'), 0.026609313503778098),\n",
              " (('like', 'them'), 0.0005476056935518915),\n",
              " (('seen', 'them'), 0.0005404003554788403),\n",
              " (('before', 'them'), 0.0016139957283634696),\n",
              " (('make', 'them'), 0.0012104967962726025)]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz68ZQ7l_2bc"
      },
      "source": [
        "count the number of distinct bigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi_pDd5o_2bc",
        "outputId": "060f3a82-80f1-4337-8dc1-cafea685b2ba"
      },
      "source": [
        "bigram_distinct = bigramcount.count()\n",
        "bigram_distinct"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "59099"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQYxiQg9_2bd"
      },
      "source": [
        "attach to each bigram its probability, i.e. $$P(ab)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trnmGMBa_2be",
        "outputId": "f780b7a6-5942-4791-e2eb-611330596311"
      },
      "source": [
        "bigramjointproba = bigramcount.#...\n",
        "bigramjointproba.take(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(('use', 'of'), 0.00013536608064434254),\n",
              " (('at', 'no'), 0.0001015245604832569),\n",
              " (('the', 'terms'), 0.00023689064112759946),\n",
              " (('12', '2019'), 1.6920760080542818e-05),\n",
              " (('PREJUDICE', 'Produced'), 1.6920760080542818e-05),\n",
              " (('Volunteers', 'and'), 5.076228024162845e-05),\n",
              " (('and', 'Prejudice'), 6.768304032217127e-05),\n",
              " (('Chapter', '4'), 3.3841520161085635e-05),\n",
              " (('Chapter', '10'), 3.3841520161085635e-05),\n",
              " (('Chapter', '12'), 3.3841520161085635e-05)]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W7oVeWB_2be"
      },
      "source": [
        "compute the SPMI and sort in descending order on the score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9l4t2Vk_2bf",
        "outputId": "5e9cbc10-376e-4821-adff-6a373e9608a9"
      },
      "source": [
        "SPMI = bigramjointproba.#...\n",
        "SPMI.take(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(('staff', 'Please'), 1019.1901893433051),\n",
              " (('he—poor', 'Eliza—to'), 1019.1901893433051),\n",
              " (('net', 'purses'), 1019.1901893433051),\n",
              " (('Italian', 'songs'), 1019.1901893433051),\n",
              " (('barbarously', 'misused'), 1019.1901893433051),\n",
              " (('weighty', 'accusation'), 1019.1901893433051),\n",
              " (('vicious', 'propensities—the'), 1019.1901893433051),\n",
              " (('untamed', 'unabashed'), 1019.1901893433051),\n",
              " (('City', 'UT'), 1019.1901893433051),\n",
              " (('Kenilworth', 'Birmingham'), 1019.1901893433051)]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyhUU7bd_2bh"
      },
      "source": [
        "## Matrix multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75wifCJz_2bh"
      },
      "source": [
        "Write a program to perform matrix multiplication using the Spark RDD operators.\n",
        "The input matrices are represented with their coordinates: each matrix is an RDD of tuples `(i,j,val)` where `i` is the line number, `j` the column number and `val` the value.\n",
        "The input matrices are provided (`matM` and `matN`).\n",
        "The output matrix is also represented with its coordinates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVTx5zcK_2bh"
      },
      "source": [
        "M = [(1,1,1),(1,2,2),(1,3,3),(2,1,2),(2,2,5),(2,3,7)]\n",
        "N = [(1,1,2),(1,2,4),(1,3,8),(2,1,1),(2,2,5),(2,3,10),(3,1,3),(3,2,6),(3,3,9)]\n",
        "\n",
        "matM = spark.sparkContext.parallelize(M)\n",
        "matN = spark.sparkContext.parallelize(N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rHdeIyO_2bh",
        "outputId": "fbb0380d-56f8-4251-e2f8-82d92b0b1ba7"
      },
      "source": [
        "matMElem = matM.#... #(i,j,v) -> (j,(i,v))\n",
        "matNElem = matN.#... #(j,k,v') -> (j,(k,v'))\n",
        "pairwiseProd = matMElem.#...\n",
        "product = pairwiseProd.#...\n",
        "product.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[((1, 1), 13),\n",
              " ((1, 2), 32),\n",
              " ((2, 3), 129),\n",
              " ((1, 3), 55),\n",
              " ((2, 2), 75),\n",
              " ((2, 1), 30)]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5ZJa3iU_2bh"
      },
      "source": [
        "##END"
      ]
    }
  ]
}