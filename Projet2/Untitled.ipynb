{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46ff0be2-e5de-41ed-ae53-2e51c8399b53",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (729492160.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_185870/729492160.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    map_type={\"nominal\" :\"string\",\"continuous\": \"float\"}%\u001b[0m\n\u001b[0m                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "attributslines=open(\"pseudo_shema.txt\",\"r\").readlines()\n",
    "types_lines=open(\"attributs_types.txt\",\"r\").readlines()\n",
    "map_type={\"nominal\" :\"string\",\"continuous\": \"float\"}%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d32c0d1d-2fca-4912-b779-b40826063c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57fae0c-ad90-4c89-89d3-59adae90f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f1f497a-e4d6-434f-a96b-100aad29c10b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_185870/2904088452.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.sql.shuffle.partitions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nombre de partitions utilisées : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.sql.shuffle.partitions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"8\")\n",
    "print(\"Nombre de partitions utilisées : \", spark.conf.get(\"spark.sql.shuffle.partitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "466c2cf2-bf88-47a8-bf50-0037a6dcc192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data already downloaded\n",
      "test data already downloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['census-income.data',\n",
       " '.ipynb_checkpoints',\n",
       " 'Untitled Document 1',\n",
       " 'census-income.test.gz',\n",
       " 'pseudo_shema.txt',\n",
       " 'census-income.test',\n",
       " 'census-income.names',\n",
       " 'test.csv',\n",
       " 'Untitled.ipynb',\n",
       " 'attributs_types.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from urllib import request\n",
    "import gzip\n",
    "drive_dir=\".\"\n",
    "url_train =  \"http://kdd.ics.uci.edu/databases/census-income/census-income.data.gz\"\n",
    "url_test =  \"http://kdd.ics.uci.edu/databases/census-income/census-income.test.gz\"\n",
    "# temp = \"/temp\"\n",
    "local_archive_train = drive_dir +\"/census-income.data.gz\"\n",
    "local_archive_test = drive_dir +\"/census-income.test.gz\"\n",
    "local_train=drive_dir +\"/census-income.data\"\n",
    "local_test= drive_dir +\"/census-income.test\"\n",
    "os.makedirs(drive_dir,exist_ok=True)\n",
    "\n",
    "\n",
    "if(os.path.isfile(local_train)):\n",
    "  print(\"train data already downloaded\")\n",
    "else:\n",
    "  print(\"downloading from URL: \", url_train, \"save in : \", local_archive_train)\n",
    "  request.urlretrieve(url_train, local_archive_train)\n",
    "  os.chdir(drive_dir)\n",
    "  print(drive_dir,local_archive_train)\n",
    "  with  gzip.open(local_archive_train,\"rb\") as gz_f:\n",
    "    with open(local_train,\"wb\") as f:\n",
    "      f.write(gz_f.read())\n",
    "\n",
    "\n",
    "if(os.path.isfile(local_archive_test)):\n",
    "  print(\"test data already downloaded\")\n",
    "else:\n",
    "  print(\"downloading from URL: \", url_test, \"save in : \", local_archive_test)\n",
    "  request.urlretrieve(url_test, local_archive_test)\n",
    "  os.chdir(drive_dir)\n",
    "  with  gzip.open(local_archive_test,\"rb\") as gz_f:\n",
    "    with open(local_test,\"wb\") as f:\n",
    "      f.write(gz_f.read())\n",
    "\n",
    "#liste des fichier des données \n",
    "os.listdir(drive_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7076fc9d-84d5-4e35-aa2c-e32c2908c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema=\"\"\"AAGE float , \n",
    "ACLSWKR string , \n",
    "ADTIND string , \n",
    "ADTOCC string , \n",
    "AHGA string , \n",
    "AHRSPAY float , \n",
    "AHSCOL string , \n",
    "AMARITL string , \n",
    "AMJIND string , \n",
    "AMJOCC string , \n",
    "ARACE string , \n",
    "AREORGN string , \n",
    "ASEX string , \n",
    "AUNMEM string , \n",
    "AUNTYPE string , \n",
    "AWKSTAT string , \n",
    "CAPGAIN float , \n",
    "CAPLOSS float , \n",
    "DIVVAL float , \n",
    "FILESTAT string , \n",
    "GRINREG string , \n",
    "GRINST string , \n",
    "HHDFMX string , \n",
    "HHDREL string , \n",
    "MARSUPWT float,\n",
    "MIGMTR1 string , \n",
    "MIGMTR3 string , \n",
    "MIGMTR4 string , \n",
    "MIGSAME string , \n",
    "MIGSUN string , \n",
    "NOEMP float , \n",
    "PARENT string , \n",
    "PEFNTVTY string , \n",
    "PEMNTVTY string , \n",
    "PENATVTY string , \n",
    "PRCITSHP string , \n",
    "SEOTR string , \n",
    "VETQVA string , \n",
    "VETYN string , \n",
    "WKSWORK float , \n",
    "YEAR string ,\n",
    "Label string\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "399b2f1b-bd76-4299-aedd-7aac85ad4d71",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'spark' has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_185870/2537713512.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/census-income.data\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/census-income.test\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'spark' has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "train_dataset = spark.read.csv(path = drive_dir + \"/census-income.data\",schema=schema).persist()\n",
    "test_dataset=spark.read.csv(path = drive_dir + \"/census-income.test\",schema=schema).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dfe0fb1-268b-4ba1-a7a9-2e44b2d8fb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AAGE': 'continuous', 'ACLSWKR': 'nominal', 'ADTIND': 'nominal', 'ADTOCC': 'nominal', 'AHGA': 'nominal', 'AHRSPAY': 'continuous', 'AHSCOL': 'nominal', 'AMARITL': 'nominal', 'AMJIND': 'nominal', 'AMJOCC': 'nominal', 'ARACE': 'nominal', 'AREORGN': 'nominal', 'ASEX': 'nominal', 'AUNMEM': 'nominal', 'AUNTYPE': 'nominal', 'AWKSTAT': 'nominal', 'CAPGAIN': 'continuous', 'CAPLOSS': 'continuous', 'DIVVAL': 'continuous', 'FILESTAT': 'nominal', 'GRINREG': 'nominal', 'GRINST': 'nominal', 'HHDFMX': 'nominal', 'HHDREL': 'nominal', 'MIGMTR1': 'nominal', 'MIGMTR3': 'nominal', 'MIGMTR4': 'nominal', 'MIGSAME': 'nominal', 'MIGSUN': 'nominal', 'NOEMP': 'continuous', 'PARENT': 'nominal', 'PEFNTVTY': 'nominal', 'PEMNTVTY': 'nominal', 'PENATVTY': 'nominal', 'PRCITSHP': 'nominal', 'SEOTR': 'nominal', 'VETQVA': 'nominal', 'VETYN': 'nominal', 'WKSWORK': 'continuous', 'YAR': 'nominal'}\n"
     ]
    }
   ],
   "source": [
    "print(dict(zip(attributs,types)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
